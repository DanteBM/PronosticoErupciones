{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando LGBM como regresor\n",
    "- Alvarado Morán Óscar\n",
    "- Bermúdez Marbán Dante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#!conda install -c conda-forge lightgbm -y\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_lgbm(X_train, y_train, X_test, y_test):\n",
    "    d_train = lgb.Dataset(X_train, label = y_train)\n",
    "    params = {}\n",
    "    params['learning_rate'] = 0.0095\n",
    "    params['boosting_type'] = 'gbdt'\n",
    "    params['objective'] = 'regression'\n",
    "    params['metric'] = 'mae'\n",
    "    params['sub_feature'] = 0.5\n",
    "    params['num_leaves'] = 30\n",
    "    params['min_data'] = 20\n",
    "    params['max_depth'] = 10\n",
    "    clf = lgb.train(params, d_train, 100) # Num_boost_round es el tercer parámetro\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_pred,y_test)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv(\"../csvs/stats_per_file2.csv\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/home/oscar/Escritorio/predict-volcanic-eruptions-ingv-oe/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_time = datos.join(train.set_index(\"segment_id\"), on = \"segment_id\")\n",
    "datos_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datos_time.iloc[:,1:-1].values\n",
    "y = datos_time.iloc[:,-1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aplicar_lgbm(X_train, y_train, X_test, y_test) # Con las estadísticas anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con las estadísticas de señales\n",
    "datos = pd.read_csv(\"../csvs/stats_per_file_signal.csv\")\n",
    "train = pd.read_csv(\"/home/oscar/Escritorio/predict-volcanic-eruptions-ingv-oe/train.csv\")\n",
    "datos_time = datos.join(train.set_index(\"segment_id\"), on = \"segment_id\")\n",
    "\n",
    "X = datos_time.iloc[:,1:-1].values\n",
    "y = datos_time.iloc[:,-1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aplicar_lgbm(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando algo así como random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE:  2580211.5837444784\n",
    "\n",
    "{'learning_rate': 0.24842943048773125, 'boosting_type': 'dart', 'objective': 'regression', 'metric': 'mae', 'sub_feature': 0.6330313130909996, 'num_leaves': 48, 'min_data': 21, 'max_depth': 27}\n",
    "\n",
    "MAE: 2553720.985319375\n",
    "\n",
    "{'learning_rate': 0.1275200906747731,\n",
    " 'boosting_type': 'dart',\n",
    " 'objective': 'regression',\n",
    " 'metric': 'mae',\n",
    " 'sub_feature': 0.4067123592984939,\n",
    " 'num_leaves': 287,\n",
    " 'min_data': 19,\n",
    " 'max_depth': 94}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(X_train, y_train, X_test, y_test, its = 50):\n",
    "    #Set the minimum error arbitrarily large\n",
    "    minimo = 99999999999999999999999 \n",
    "    pp = {}\n",
    "    count = 0 #Used for keeping track of the iteration number\n",
    "    maes = []\n",
    "    pars = []\n",
    "    #How many runs to perform using randomly selected hyperparameters\n",
    "    iterations = its\n",
    "    for i in range(iterations):\n",
    "        print('iteration number', count)\n",
    "        count += 1 #increment count\n",
    "        params = {} #initialize parameters\n",
    "        try:\n",
    "            d_train = lgb.Dataset(X_train, label = y_train) #Load in data\n",
    "            params['learning_rate'] = np.random.uniform(0, 1)\n",
    "            params['boosting_type'] = np.random.choice(['gbdt', 'dart', 'goss'])\n",
    "            params['objective'] = 'regression'\n",
    "            params['metric'] = 'mae'\n",
    "            params['sub_feature'] = np.random.uniform(0, 1)\n",
    "            params['num_leaves'] = np.random.randint(20, 300)\n",
    "            params['min_data'] = np.random.randint(10, 100)\n",
    "            params['max_depth'] = np.random.randint(5, 200)\n",
    "            iterations = np.random.randint(10, 10000)\n",
    "            #print(params, iterations)#Train using selected parameters\n",
    "            clf = lgb.train(params, d_train, iterations)\n",
    "            y_pred = clf.predict(X_test) #Create predictions on test set\n",
    "            mae = mean_absolute_error(y_pred,y_test)    \n",
    "            #print('MAE:', mae)\n",
    "            maes.append(mae)\n",
    "            pars.append(params)\n",
    "            if mae < minimo:\n",
    "                minimo = mae\n",
    "                pp = params\n",
    "        except: #in case something goes wrong\n",
    "            print('failed with')\n",
    "            print(params)\n",
    "    return maes, pars, minimo, pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Con las estadísticas de señales\n",
    "datos = pd.read_csv(\"../csvs/stats_per_file_signal.csv\")\n",
    "train = pd.read_csv(\"/home/oscar/Escritorio/predict-volcanic-eruptions-ingv-oe/train.csv\")\n",
    "datos_time = datos.join(train.set_index(\"segment_id\"), on = \"segment_id\")\n",
    "\n",
    "X = datos_time.iloc[:,1:-1].values\n",
    "y = datos_time.iloc[:,-1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "maes1, pars1, minimo1, pp1 = random_search(X_train, y_train, X_test, y_test, its = 200)\n",
    "print(minimo1)\n",
    "pp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Con las estadísticas base\n",
    "datos = pd.read_csv(\"../csvs/stats_per_file2.csv\")\n",
    "train = pd.read_csv(\"/home/oscar/Escritorio/predict-volcanic-eruptions-ingv-oe/train.csv\")\n",
    "datos_time = datos.join(train.set_index(\"segment_id\"), on = \"segment_id\")\n",
    "\n",
    "X = datos_time.iloc[:,1:-1].values\n",
    "y = datos_time.iloc[:,-1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "maes2, pars2, minimo2, pp2 = random_search(X_train, y_train, X_test, y_test, its = 100)\n",
    "print(minimo2)\n",
    "pp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando con los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "datos = pd.read_csv(\"../csvs/stats_per_file2.csv\")\n",
    "train = pd.read_csv(\"/home/oscar/Escritorio/predict-volcanic-eruptions-ingv-oe/train.csv\")\n",
    "datos_time = datos.join(train.set_index(\"segment_id\"), on = \"segment_id\")\n",
    "\n",
    "X = datos_time.iloc[:,1:-1].values\n",
    "y = datos_time.iloc[:,-1].values\n",
    "\n",
    "d_train = lgb.Dataset(X, label = y)\n",
    "params['learning_rate'] = 0.1275200906747731\n",
    "params['boosting_type'] = 'dart'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'mae'\n",
    "params['sub_feature'] = 0.4067123592984939\n",
    "params['num_leaves'] = 287\n",
    "params['min_data'] = 19\n",
    "params['max_depth'] = 94\n",
    "iterations = 10000\n",
    "clf = lgb.train(params, d_train, iterations)\n",
    "\n",
    "# Prueba\n",
    "#X_test = \n",
    "y_pred = clf.predict(X_test) #Create predictions on test set\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
